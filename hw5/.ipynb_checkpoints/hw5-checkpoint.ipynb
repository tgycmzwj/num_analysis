{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple iteration for systems of linear equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, generate a random diagonally dominant matrix, for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.51915195e+01, 6.22108771e-01, 4.37727739e-01, 7.85358584e-01,\n",
       "        7.79975808e-01, 2.72592605e-01, 2.76464255e-01, 8.01872178e-01,\n",
       "        9.58139354e-01, 8.75932635e-01],\n",
       "       [3.57817270e-01, 1.55009951e+01, 6.83462935e-01, 7.12702027e-01,\n",
       "        3.70250755e-01, 5.61196186e-01, 5.03083165e-01, 1.37684496e-02,\n",
       "        7.72826622e-01, 8.82641191e-01],\n",
       "       [3.64885984e-01, 6.15396178e-01, 1.50753812e+01, 3.68824006e-01,\n",
       "        9.33140102e-01, 6.51378143e-01, 3.97202578e-01, 7.88730143e-01,\n",
       "        3.16836122e-01, 5.68098653e-01],\n",
       "       [8.69127390e-01, 4.36173424e-01, 8.02147642e-01, 1.51437668e+01,\n",
       "        7.04260971e-01, 7.04581308e-01, 2.18792106e-01, 9.24867629e-01,\n",
       "        4.42140755e-01, 9.09315959e-01],\n",
       "       [5.98092228e-02, 1.84287084e-01, 4.73552788e-02, 6.74880944e-01,\n",
       "        1.55946248e+01, 5.33310163e-01, 4.33240627e-02, 5.61433080e-01,\n",
       "        3.29668446e-01, 5.02966833e-01],\n",
       "       [1.11894318e-01, 6.07193706e-01, 5.65944643e-01, 6.76406199e-03,\n",
       "        6.17441709e-01, 1.59121229e+01, 7.90524133e-01, 9.92081466e-01,\n",
       "        9.58801762e-01, 7.91964135e-01],\n",
       "       [2.85250960e-01, 6.24916705e-01, 4.78093796e-01, 1.95675179e-01,\n",
       "        3.82317452e-01, 5.38736851e-02, 1.54516484e+01, 9.82004742e-01,\n",
       "        1.23942700e-01, 1.19380898e-01],\n",
       "       [7.38523056e-01, 5.87303633e-01, 4.71632534e-01, 1.07126817e-01,\n",
       "        2.29218565e-01, 8.99965195e-01, 4.16753538e-01, 1.55358517e+01,\n",
       "        6.20851659e-03, 3.00641706e-01],\n",
       "       [4.36893172e-01, 6.12148997e-01, 9.18198075e-01, 6.25736670e-01,\n",
       "        7.05997565e-01, 1.49833716e-01, 7.46063409e-01, 8.31006992e-01,\n",
       "        1.56337258e+01, 4.38309881e-01],\n",
       "       [1.52572775e-01, 5.68409615e-01, 5.28224278e-01, 9.51428764e-01,\n",
       "        4.80359179e-01, 5.02559563e-01, 5.36878193e-01, 8.19202067e-01,\n",
       "        5.71156381e-02, 1.56694217e+01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "rndm = np.random.RandomState(1234)\n",
    "\n",
    "n = 10\n",
    "A = rndm.uniform(size=(n, n)) + np.diagflat([15]*n)\n",
    "b = rndm.uniform(size=n)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I.  Jacobi iteration\n",
    "\n",
    "Given\n",
    "\n",
    "$$\n",
    "A x = b\n",
    "$$\n",
    "\n",
    "separate the diagonal part $D$,\n",
    "\n",
    "$$ A = D + (A - D) $$\n",
    "\n",
    "and write\n",
    "\n",
    "$$\n",
    "x = D^{-1} (D - A) x + D^{-1} b\\;.\n",
    "$$\n",
    "\n",
    "Then iterate\n",
    "\n",
    "$$\n",
    "x_{n + 1} = B x_{n} + c\\;,\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "B = D^{-1} (A - D) \\qquad \\text{and} \\qquad c = D^{-1} b\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct the matrix and the r.h.s. for the Jacobi iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.62210877, -0.43772774, -0.78535858, -0.77997581,\n",
       "        -0.27259261, -0.27646426, -0.80187218, -0.95813935, -0.87593263],\n",
       "       [-0.35781727,  0.        , -0.68346294, -0.71270203, -0.37025075,\n",
       "        -0.56119619, -0.50308317, -0.01376845, -0.77282662, -0.88264119],\n",
       "       [-0.36488598, -0.61539618,  0.        , -0.36882401, -0.9331401 ,\n",
       "        -0.65137814, -0.39720258, -0.78873014, -0.31683612, -0.56809865],\n",
       "       [-0.86912739, -0.43617342, -0.80214764,  0.        , -0.70426097,\n",
       "        -0.70458131, -0.21879211, -0.92486763, -0.44214076, -0.90931596],\n",
       "       [-0.05980922, -0.18428708, -0.04735528, -0.67488094,  0.        ,\n",
       "        -0.53331016, -0.04332406, -0.56143308, -0.32966845, -0.50296683],\n",
       "       [-0.11189432, -0.60719371, -0.56594464, -0.00676406, -0.61744171,\n",
       "         0.        , -0.79052413, -0.99208147, -0.95880176, -0.79196414],\n",
       "       [-0.28525096, -0.62491671, -0.4780938 , -0.19567518, -0.38231745,\n",
       "        -0.05387369,  0.        , -0.98200474, -0.1239427 , -0.1193809 ],\n",
       "       [-0.73852306, -0.58730363, -0.47163253, -0.10712682, -0.22921857,\n",
       "        -0.89996519, -0.41675354,  0.        , -0.00620852, -0.30064171],\n",
       "       [-0.43689317, -0.612149  , -0.91819808, -0.62573667, -0.70599757,\n",
       "        -0.14983372, -0.74606341, -0.83100699,  0.        , -0.43830988],\n",
       "       [-0.15257277, -0.56840962, -0.52822428, -0.95142876, -0.48035918,\n",
       "        -0.50255956, -0.53687819, -0.81920207, -0.05711564,  0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag_1d = np.diag(A)\n",
    "\n",
    "B = -A.copy()\n",
    "np.fill_diagonal(B, 0)\n",
    "\n",
    "D = np.diag(diag_1d)\n",
    "invD = np.diag(1./diag_1d)\n",
    "BB = invD @ B \n",
    "c = invD @ b\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03919429,  0.03780037,  0.04283232,  0.02365951,  0.05745031,\n",
       "       -0.00030244, -0.00577279,  0.03177549, -0.00422849,  0.05284648])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity checks\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "assert_allclose(-B + D, A)\n",
    "\n",
    "\n",
    "# xx is a \"ground truth\" solution, compute it using a direct method\n",
    "xx = np.linalg.solve(A, b)\n",
    "\n",
    "np.testing.assert_allclose(A@xx, b)\n",
    "np.testing.assert_allclose(D@xx, B@xx + b)\n",
    "np.testing.assert_allclose(xx, BB@xx + c)\n",
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that $\\| B\\| \\leqslant 1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36436161983015336"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(BB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the Jacobi iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 50\n",
    "\n",
    "x0 = np.ones(n)\n",
    "x = x0\n",
    "for _ in range(n_iter):\n",
    "    x = BB @ x + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  2.22044605e-16,  0.00000000e+00, -1.11022302e-16,\n",
       "        0.00000000e+00,  0.00000000e+00, -2.08166817e-17,  0.00000000e+00,\n",
       "        0.00000000e+00,  2.22044605e-16])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the result:\n",
    "\n",
    "A @ x - b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task I.1\n",
    "\n",
    "Collect the proof-of-concept above into a single function implementing the Jacobi iteration. This function should receive the r.h.s. matrix $A$, the l.h.s. vector `b`, and the number of iterations to perform.\n",
    "\n",
    "\n",
    "The matrix $A$ in the illustration above is strongly diagonally dominant, by construction. \n",
    "What happens if the diagonal matrix elements of $A$ are made smaller? Check the convergence of the Jacobi iteration, and check the value of the norm of $B$.\n",
    "\n",
    "(20% of the total grade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03919429,  0.03780037,  0.04283232,  0.02365951,  0.05745031,\n",
       "       -0.00030244, -0.00577279,  0.03177549, -0.00422849,  0.05284648])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... ENTER YOUR CODE HERE ...\n",
    "def jacobi_iteration(x,A,b,iter_num=1000):\n",
    "    #matrix D\n",
    "    diag_1d = np.diag(A)\n",
    "    D = np.diag(diag_1d)\n",
    "    #inverse of D\n",
    "    invD = np.diag(1./diag_1d)\n",
    "    #matrix B\n",
    "    B = -A.copy()\n",
    "    np.fill_diagonal(B, 0)\n",
    "    BB = invD @ B \n",
    "    #rhs vector\n",
    "    c = invD @ b\n",
    "    #iterate\n",
    "    iters=1\n",
    "    while iters<iter_num:\n",
    "        x=np.dot(BB,x)+c\n",
    "        iters=iters+1\n",
    "    return x\n",
    "\n",
    "x=jacobi_iteration(x0,A,b,iter_num=1000)   \n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Seidel's iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task II.1\n",
    "\n",
    "Implement the Seidel's iteration. \n",
    "\n",
    "Test it on a random matrix. Study the convergence of iterations, relate to the norm of the iteration matrix.\n",
    "\n",
    "(30% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03919429,  0.03780037,  0.04283232,  0.02365951,  0.05745031,\n",
       "       -0.00030244, -0.00577279,  0.03177549, -0.00422849,  0.05284648])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... ENTER YOUR CODE HERE ...\n",
    "def seidel_iteration(x,A,b,iter_num=1000):\n",
    "    #matrix U\n",
    "    U=np.zeros_like(A)\n",
    "    for i in range(A.shape[0]):\n",
    "        for j in range(i+1,A.shape[0]):\n",
    "            U[i][j]=A[i][j]\n",
    "    LHS=A-U\n",
    "    iters=0\n",
    "    while iters<iter_num:\n",
    "        x=np.dot(np.linalg.inv(LHS),b-np.dot(U,x))\n",
    "        iters=iters+1\n",
    "    return x\n",
    "x=seidel_iteration(x0,A,b,iter_num=1000)   \n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Minimum residual scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task III.1\n",
    "\n",
    "Implement the $\\textit{minimum residual}$ scheme: an explicit non-stationary method, where at each step you select the iteration parameter $\\tau_n$ to minimize the residual $\\mathbf{r}_{n+1}$ given $\\mathbf{r}_n$. Test it on a random matrix, study the convergence to the solution, in terms of the norm of the residual and the deviation from the ground truth solution (which you can obtain using a direct method). Study how the iteration parameter $\\tau_n$ changes as iterations progress.\n",
    "\n",
    "(50% of the grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... ENTER YOUR CODE HERE ...\n",
    "def mrm_iteration(x,A,b,iter_num=1000):\n",
    "    iters=0\n",
    "    x,b=x.reshape([-1,1]),b.reshape([-1,1])\n",
    "    while iters<iter_num:\n",
    "        #current residual\n",
    "        r=(np.dot(A,x)-b).reshape([-1,1])\n",
    "        #Ar\n",
    "        Ar=np.dot(A,r)\n",
    "        #current tau\n",
    "        tau=np.sum(np.dot(r.T,Ar))/np.sum(Ar**2)\n",
    "        #update\n",
    "        x=x-tau*r\n",
    "        iters=iters+1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03919429],\n",
       "       [ 0.03780037],\n",
       "       [ 0.04283232],\n",
       "       [ 0.02365951],\n",
       "       [ 0.05745031],\n",
       "       [-0.00030244],\n",
       "       [-0.00577279],\n",
       "       [ 0.03177549],\n",
       "       [-0.00422849],\n",
       "       [ 0.05284648]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrm_iteration(x0,A,b,iter_num=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
